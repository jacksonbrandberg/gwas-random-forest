{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>9991</th>\n",
       "      <th>9992</th>\n",
       "      <th>9993</th>\n",
       "      <th>9994</th>\n",
       "      <th>9995</th>\n",
       "      <th>9996</th>\n",
       "      <th>9997</th>\n",
       "      <th>9998</th>\n",
       "      <th>9999</th>\n",
       "      <th>10000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1350 rows Ã— 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1  2  3  4  5  6  7  8  9  10  ...  9991  9992  9993  9994  9995  9996  \\\n",
       "0     1  0  0  0  0  0  0  0  0   0  ...     0     0     0     0     0     0   \n",
       "1     1  0  0  0  0  0  0  2  0   0  ...     0     0     0     0     0     0   \n",
       "2     1  0  0  0  0  0  0  2  0   0  ...     0     0     0     0     0     0   \n",
       "3     1  0  0  0  0  0  0  0  0   0  ...     0     0     0     0     0     0   \n",
       "4     1  0  0  0  0  0  0  0  0   0  ...     0     0     0     0     0     0   \n",
       "...  .. .. .. .. .. .. .. .. ..  ..  ...   ...   ...   ...   ...   ...   ...   \n",
       "1345  1  0  0  0  0  0  0  0  0   0  ...     0     0     0     0     0     0   \n",
       "1346  1  0  0  0  0  0  0  0  0   0  ...     0     0     0     0     0     0   \n",
       "1347  1  0  0  0  0  0  0  0  0   0  ...     0     0     0     0     0     0   \n",
       "1348  1  0  0  0  0  0  0  0  0   0  ...     0     0     0     0     0     0   \n",
       "1349  1  0  0  0  0  0  0  1  0   0  ...     0     0     0     0     0     0   \n",
       "\n",
       "      9997  9998  9999  10000  \n",
       "0        0     0     0      0  \n",
       "1        0     0     0      0  \n",
       "2        0     0     0      0  \n",
       "3        0     0     0      0  \n",
       "4        0     0     0      0  \n",
       "...    ...   ...   ...    ...  \n",
       "1345     0     0     0      0  \n",
       "1346     0     0     0      0  \n",
       "1347     0     0     0      0  \n",
       "1348     0     0     0      0  \n",
       "1349     0     0     0      0  \n",
       "\n",
       "[1350 rows x 10000 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the data here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import os\n",
    "df = pd.read_csv('../data/chrom_11_clean.csv', )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-8dc6bbe370c0>:9: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X=np.nan_to_num((X-Xmean)/Xstd) # Standardized genotype matrix based on means and standard deviations\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "n=X.shape[0]\n",
    "p=X.shape[1]\n",
    "ncausal_SNPs=30\n",
    "\n",
    "## Normalize genotype data:\n",
    "Xmean= np.mean(X, axis=0) #mean of each column, which corresponds to a SNP locus\n",
    "Xstd= np.std(X,axis=0) #standard deviation of each column\n",
    "X=np.nan_to_num((X-Xmean)/Xstd) # Standardized genotype matrix based on means and standard deviations\n",
    "# of each SNP locus. This is the final X. I use np.nan_to_num in case we get NaN values due to \n",
    "# 0 division, i.e. if everything in a column is 0, the mean and standard deviation will also be 0, \n",
    "# then we will get NaN values. np.nan_to_num turns NaNs into \"0\"s. This seemed like a good idea to me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "H2= 0.8 #80% of phenotypic variation is explained by genotype (heritability)\n",
    "rho= 1 #100% of H^2 is explained by additive effects \n",
    "\n",
    "causal_SNPs_list = []\n",
    "random_states_list = [1,2,3,4,5,6,7,8,9,10,11]\n",
    "y_list = []\n",
    "\n",
    "for i in range(0,11):\n",
    "    random_state = random_states_list[i]\n",
    "    causalSNPs=np.random.randint(low=0, high=10000, size=ncausal_SNPs)\n",
    "    causal_SNPs_list.append(causalSNPs)\n",
    "    Xadditive=X[:, causalSNPs] #the values for causal SNPs.\n",
    "    betaAdd= np.repeat(1, ncausal_SNPs)#additive effect sizes initializes as \"1\"\n",
    "    y_additive=np.dot(Xadditive, betaAdd) #initialize the value of the portion of phenotypic variation\n",
    "    # caused by the additive effects as XB.\n",
    "    betaAdd= betaAdd * np.sqrt(H2*rho/np.var(y_additive)) #Update additive effect sizes based on H^2, rho, and variation\n",
    "    #in y_additive.\n",
    "    y_additive=np.dot(Xadditive, betaAdd) #final value of y_additive, updated.\n",
    "    y_additive=y_additive.reshape(n,1)\n",
    "    y_noise = np.random.normal(size=n)\n",
    "    y_noise = y_noise * np.sqrt((1 - H2-0.1) / np.var(y_noise))\n",
    "    y_noise=y_noise.reshape(n,1)\n",
    "\n",
    "    y = y_additive + y_noise #np.add(y_additive.reshape(n, 1), y_noise.reshape(n, 1), y_PC, y_epi.reshape(n, 1))\n",
    "    y_list.append(y)\n",
    "    # np.savetxt(\"timing/X_1000_1000.csv\", X, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, fbeta_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, fbeta_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLpipe_KFold_RMSE(X,ML_algo,param_grid):\n",
    "    '''\n",
    "    This function splits the data to other/test (80/20) and then applies KFold with 4 folds to other.\n",
    "    The RMSE is minimized in cross-validation.\n",
    "    '''\n",
    "    \n",
    "    test_scores = []\n",
    "    best_models = []\n",
    "    causal_SNPs_list = []\n",
    "    top_features_list = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        \n",
    "        random_state = i * 112\n",
    "        causalSNPs = np.random.randint(low=0, high=10000, size=ncausal_SNPs)\n",
    "        causal_SNPs_list.append(causalSNPs)\n",
    "        Xadditive = X[:, causalSNPs] #the values for causal SNPs.\n",
    "        betaAdd = np.repeat(1, ncausal_SNPs)#additive effect sizes initializes as \"1\"\n",
    "        y_additive = np.dot(Xadditive, betaAdd) #initialize the value of the portion of phenotypic variation\n",
    "        # caused by the additive effects as XB.\n",
    "        betaAdd = betaAdd * np.sqrt(H2*rho/np.var(y_additive)) #Update additive effect sizes based on H^2, rho, and variation\n",
    "        #in y_additive.\n",
    "        y_additive = np.dot(Xadditive, betaAdd) #final value of y_additive, updated.\n",
    "        y_additive = y_additive.reshape(n,1)\n",
    "        y_noise = np.random.normal(size=n)\n",
    "        y_noise = y_noise * np.sqrt((1 - H2-0.1) / np.var(y_noise))\n",
    "        y_noise = y_noise.reshape(n,1)\n",
    "        y = y_additive + y_noise #np.add(y_additive.reshape(n, 1), y_noise.reshape(n, 1), y_PC, y_epi.reshape(n, 1))\n",
    "        \n",
    "        X_other, X_test, y_other, y_test = train_test_split(X,y,test_size = 0.2,random_state=random_state)\n",
    "        \n",
    "        kf = KFold(n_splits=4,shuffle=True,random_state= random_state)  \n",
    "        \n",
    "        grid = GridSearchCV(estimator = ML_algo, param_grid=param_grid,scoring = 'neg_root_mean_squared_error',\n",
    "                    cv=kf, return_train_score = True, verbose=True, n_jobs = -1)\n",
    "        \n",
    "        grid.fit(X_other, y_other.ravel())\n",
    "        \n",
    "        results = pd.DataFrame(grid.cv_results_)\n",
    "        \n",
    "        print('best model parameters:',grid.best_params_)\n",
    "        best_models.append(grid)\n",
    "        y_test_pred = best_models[-1].predict(X_test)\n",
    "        test_scores.append(mean_squared_error(y_test,y_test_pred)**(0.5))\n",
    "        \n",
    "        feature_importances = grid.best_estimator_.feature_importances_\n",
    "        all_snps = np.array(list(range(0, 10000)))\n",
    "        \n",
    "        data={'feature_names':all_snps,'feature_importance':feature_importances}\n",
    "        fi_df = pd.DataFrame(data)\n",
    "        fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "        \n",
    "        top_features = fi_df['feature_names']\n",
    "        top_features = np.array(top_features)\n",
    "        top_features_list.append(top_features)        \n",
    "    \n",
    "    print(np.mean(test_scores))\n",
    "    print(np.std(test_scores))\n",
    "    return best_models, test_scores, causal_SNPs_list, top_features_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   15.4s\n",
      "[Parallel(n_jobs=-1)]: Done 144 out of 144 | elapsed:  8.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model parameters: {'max_depth': 30, 'max_features': 10000, 'n_estimators': 100}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done 144 out of 144 | elapsed:  6.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model parameters: {'max_depth': 30, 'max_features': 10000, 'n_estimators': 100}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=-1)]: Done 144 out of 144 | elapsed:  9.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model parameters: {'max_depth': 100, 'max_features': 10000, 'n_estimators': 100}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   19.2s\n",
      "[Parallel(n_jobs=-1)]: Done 144 out of 144 | elapsed: 10.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model parameters: {'max_depth': 30, 'max_features': 5000, 'n_estimators': 100}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done 144 out of 144 | elapsed:  6.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model parameters: {'max_depth': 100, 'max_features': 10000, 'n_estimators': 100}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=-1)]: Done 144 out of 144 | elapsed:  7.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model parameters: {'max_depth': 100, 'max_features': 10000, 'n_estimators': 100}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=-1)]: Done 144 out of 144 | elapsed:  6.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model parameters: {'max_depth': 300, 'max_features': 5000, 'n_estimators': 100}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=-1)]: Done 144 out of 144 | elapsed:  6.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model parameters: {'max_depth': 300, 'max_features': 5000, 'n_estimators': 100}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=-1)]: Done 144 out of 144 | elapsed:  5.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model parameters: {'max_depth': 100, 'max_features': 10000, 'n_estimators': 100}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   15.1s\n",
      "[Parallel(n_jobs=-1)]: Done 144 out of 144 | elapsed:  6.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model parameters: {'max_depth': 100, 'max_features': 5000, 'n_estimators': 100}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=-1)]: Done 144 out of 144 | elapsed:  7.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model parameters: {'max_depth': 100, 'max_features': 10000, 'n_estimators': 100}\n",
      "0.7747048825404477\n",
      "0.1567726102477407\n",
      "[[3202, 7512, 7525, 454, 1319, 3563, 8779, 6846, 5715, 3412, 1332, 4820, 7159, 2456, 7518, 4799], [1827, 8900, 357, 134, 5829, 7400, 4265, 8554, 479, 915, 2196, 7477, 4694, 8025, 7386, 1661, 6431], [7072, 772, 5349, 7402, 875, 1868, 6285, 722, 7833, 3159, 4761, 4122, 8923], [4835, 1637, 6216, 1320, 4520, 9165, 6574, 1168, 6705, 7506, 1075, 5844, 6740, 4821, 18, 5112, 6295], [4387, 7876, 9894, 6247, 6344, 8649, 9962, 6539, 8844, 4176, 1169, 8145, 8400, 9206, 3736, 3679], [2592, 7359, 6245, 6537, 4394, 6891, 1644, 4525, 4622, 144, 7766, 4855, 728, 410, 8092, 1501, 9695], [8289, 1220, 1962, 8206, 6353, 6706, 3345, 116, 7445, 1010, 1437, 3710], [2144, 7203, 388, 3369, 398, 9742, 974, 1909, 7061, 5176, 4667, 3484, 893], [1383, 5834, 7947, 3404, 2861, 2222, 2735, 2762, 9263, 589, 3539, 9420, 6453, 6963, 407], [9537, 4738, 3907, 7397, 2791, 940, 8206, 463, 3956, 2742, 9399, 858, 3421], [7105, 7049, 6669, 6189, 2095, 8752, 4335, 5873, 3251, 2868, 9207, 5338, 732, 5823]]\n"
     ]
    }
   ],
   "source": [
    "ML_algo = RandomForestRegressor()\n",
    "param_grid = {'n_estimators':[100],\n",
    "             'max_depth':[1, 3, 10, 30, 100,300],\n",
    "             'max_features':[10, 100, 500, 1000, 5000, 10000]}\n",
    "\n",
    "models, scores, causal_SNPs_list, top_features_list = MLpipe_KFold_RMSE(X,ML_algo,param_grid)\n",
    "print(captured_SNPs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49393939393939396"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_captured = []\n",
    "for i in range(len(captured_SNPs_list)):\n",
    "    captured_percent = len(captured_SNPs_list[i])/ncausal_SNPs\n",
    "    percentage_captured.append(captured_percent)\n",
    "np.mean(percentage_captured)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run again on different hyperparameter grid to further fine-tune. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  8.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model parameters: {'max_depth': 100, 'max_features': 8000, 'n_estimators': 100}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  8.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model parameters: {'max_depth': 300, 'max_features': 8000, 'n_estimators': 100}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  8.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model parameters: {'max_depth': 30, 'max_features': 10000, 'n_estimators': 100}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 12.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model parameters: {'max_depth': 30, 'max_features': 6000, 'n_estimators': 100}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  9.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model parameters: {'max_depth': 30, 'max_features': 8000, 'n_estimators': 100}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  9.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model parameters: {'max_depth': 30, 'max_features': 6000, 'n_estimators': 100}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  7.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model parameters: {'max_depth': 300, 'max_features': 8000, 'n_estimators': 100}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 11.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model parameters: {'max_depth': 30, 'max_features': 8000, 'n_estimators': 100}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 11.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model parameters: {'max_depth': 100, 'max_features': 10000, 'n_estimators': 100}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 10.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model parameters: {'max_depth': 100, 'max_features': 6000, 'n_estimators': 100}\n",
      "0.7186834548884311\n",
      "0.14596324533357619\n"
     ]
    }
   ],
   "source": [
    "ML_algo = RandomForestRegressor()\n",
    "param_grid = {'n_estimators':[100],\n",
    "             'max_depth':[30, 100, 300],\n",
    "             'max_features':[2000, 4000, 6000, 8000, 10000]}\n",
    "\n",
    "models, scores, causal_SNPs_list, top_features_list = MLpipe_KFold_RMSE(X,ML_algo,param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "captured_top_30 = []\n",
    "captured_top_100 = []\n",
    "captured_top_1000 = []\n",
    "captured_top_30_p = []\n",
    "captured_top_100_p = []\n",
    "captured_top_1000_p = []\n",
    "\n",
    "for i in range(len(top_features_list)):\n",
    "    top_features = top_features_list[i]\n",
    "    causal_SNPs = causal_SNPs_list[i]\n",
    "    top_30 = top_features_list[i][0:30]\n",
    "    top_100 = top_features_list[i][0:100]\n",
    "    top_1000 = top_features_list[i][0:1000]\n",
    "    captured_SNPs_30 = list(set(top_30).intersection(causal_SNPs))\n",
    "    captured_SNPs_100 = list(set(top_100).intersection(causal_SNPs))\n",
    "    captured_SNPs_1000 = list(set(top_1000).intersection(causal_SNPs))\n",
    "    captured_top_30.append(captured_SNPs_30)\n",
    "    captured_top_100.append(captured_SNPs_100)\n",
    "    captured_top_1000.append(captured_SNPs_1000)\n",
    "    captured_top_30_p.append(len(captured_SNPs_30)/ncausal_SNPs)\n",
    "    captured_top_100_p.append(len(captured_SNPs_100)/ncausal_SNPs)\n",
    "    captured_top_1000_p.append(len(captured_SNPs_1000)/ncausal_SNPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49333333333333335\n",
      "0.08537498983243798\n",
      "0.6900000000000001\n",
      "0.08306623862918078\n",
      "0.7233333333333334\n",
      "0.07000000000000005\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(captured_top_30_p))\n",
    "print(np.std(captured_top_30_p))\n",
    "print(np.mean(captured_top_100_p))\n",
    "print(np.std(captured_top_100_p))\n",
    "print(np.mean(captured_top_1000_p))\n",
    "print(np.std(captured_top_1000_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_30 = np.mean(captured_top_30_p)\n",
    "prop_100 = np.mean(captured_top_100_p)\n",
    "prop_1000 = np.mean(captured_top_1000_p)\n",
    "std_30 = np.std(captured_top_30_p)\n",
    "std_100 = np.std(captured_top_100_p)\n",
    "std_1000 = np.std(captured_top_1000_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = [prop_30, prop_100, prop_1000]\n",
    "stds = [std_30, std_100, std_1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_top_30_p = [prop_30 - 2*std_30, prop_30+ 2*std_30]\n",
    "range_top_100_p = [prop_100 - 2*std_100, prop_100+ 2*std_100]\n",
    "range_top_1000_p = [prop_1000 - 2*std_1000, prop_1000+ 2*std_1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32258335366845736, 0.6640833129982093]\n",
      "[0.5238675227416385, 0.8561324772583616]\n",
      "[0.5833333333333333, 0.8633333333333335]\n"
     ]
    }
   ],
   "source": [
    "print(range_top_30_p)\n",
    "print(range_top_100_p)\n",
    "print(range_top_1000_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ErrorbarContainer object of 3 artists>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "matplotlib.pyplot.errorbar(props, stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captured_SNPs_1 = list(set(top_features).intersection(causalSNPs))\n",
    "captured_SNPs_list.append(captured_SNPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trains = []\n",
    "X_tests = []\n",
    "y_trains = []\n",
    "y_tests = []\n",
    "for i in range(0,3):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y_list[i],test_size = 0.2, random_state=112)\n",
    "    #y_train = y_train.reshape(-1,1)\n",
    "    #y_test = y_test.reshape(-1,1)\n",
    "    X_trains.append(X_train)\n",
    "    y_trains.append(y_train)\n",
    "    X_tests.append(X_test)\n",
    "    y_tests.append(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-12ac1829bf51>:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_trains[0],y_trains[0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=30, random_state=112)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestRegressor(n_estimators=100,max_depth=30,random_state=112)\n",
    "clf.fit(X_trains[0],y_trains[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_1 = clf.predict(X_tests[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.35051613, -0.1938484 , -0.37275632,  1.39358634, -0.08542554,\n",
       "       -0.15766576, -0.71454069, -0.12424734, -0.23411722, -0.4968749 ,\n",
       "        0.66385013,  0.36860667,  0.26644805, -0.69086835,  0.2800884 ,\n",
       "       -0.81723968,  0.38314932,  0.62413684,  0.17702072, -0.06957111,\n",
       "        0.4685548 ,  0.80298139, -0.6820792 , -0.42423175, -0.29771865,\n",
       "        0.03992219,  0.33756828, -0.34691656, -0.73281818,  0.42245365,\n",
       "       -0.51856676, -0.41291133, -0.37585263,  1.48471915,  1.13098465,\n",
       "        0.56142139,  1.37927007, -0.30810007, -0.02974392, -0.29330936,\n",
       "       -0.07069375, -0.36175083, -0.37387502, -0.28568778, -0.33708043,\n",
       "       -0.68138409,  0.41371924, -0.32529278,  0.03931023, -0.17113523,\n",
       "       -0.03728017, -0.0772031 , -0.13019436, -0.13689651, -0.61352603,\n",
       "        0.83066629, -0.13107476, -0.32493661, -0.09095916, -0.06391949,\n",
       "       -0.02391122, -0.1413972 ,  0.91414202, -0.65630648, -0.23041476,\n",
       "       -0.05801104, -0.1740946 , -0.57145216,  0.27019669,  0.67237061,\n",
       "        0.27478621, -0.92178488, -0.46661026, -0.71006059,  0.41865758,\n",
       "       -0.09551266, -0.09740981, -0.4147795 , -0.73171685,  0.50688226,\n",
       "       -0.27345483, -0.19175111, -0.60913533, -0.19550116,  0.30381104,\n",
       "       -0.06847986, -0.31401395,  0.00903254,  0.23555426, -0.29242189,\n",
       "       -0.12225665,  1.38620241,  0.2862561 ,  0.08846426, -0.08689668,\n",
       "       -0.25862928,  1.16999937,  0.00565532, -0.30846178, -0.32974323,\n",
       "        1.39338133,  0.22681171, -0.41716998,  0.26877353, -0.37156184,\n",
       "       -0.261105  ,  0.11060192, -0.27499457, -0.33323768, -0.46603383,\n",
       "       -0.32545593, -0.53842741, -0.26643545,  0.25245162,  0.30334639,\n",
       "       -0.14136942, -0.5697643 , -0.32592141, -0.25016169, -0.34744359,\n",
       "       -0.31347565,  1.71825759,  0.28703132,  0.0806727 , -0.43978231,\n",
       "        0.15935731, -0.43538607, -0.59097159,  0.09407331, -0.10734728,\n",
       "       -0.15234313,  0.02144713, -0.0581994 , -0.08566996,  0.39710813,\n",
       "       -0.59980323, -0.65055081,  1.33116974, -0.38138882, -0.66240773,\n",
       "       -0.74320929, -0.68460262, -0.33375276, -0.53028428, -0.53840155,\n",
       "       -0.36113349, -0.05443156, -0.09469549,  0.13998972, -0.2307198 ,\n",
       "       -0.2741526 , -0.10193253, -0.18460491, -0.10394001, -0.17610744,\n",
       "       -0.7717341 , -0.14571418, -0.23872208, -0.82331668,  0.93161917,\n",
       "       -0.05271391, -0.08409681,  0.23848737, -0.70390358,  0.0629536 ,\n",
       "       -0.16374304, -0.25855527, -0.11247546, -0.37400412, -0.59273478,\n",
       "       -0.82173665, -0.06305576,  0.21801146, -0.69946843,  0.09472977,\n",
       "       -0.03137496,  0.11198944, -0.7812561 , -0.31841132, -0.32078221,\n",
       "       -0.54439407, -0.06283817,  0.51824741,  0.13136678, -0.27878439,\n",
       "       -0.09681371, -0.40811719, -0.06159646,  1.42640236, -0.29152212,\n",
       "       -0.24003375, -0.70511323, -0.92223498, -0.82492732, -0.56165723,\n",
       "       -0.17055039, -0.38994434, -0.22597897, -0.45291654, -0.43648964,\n",
       "       -0.39723788, -0.34798075, -0.52427952,  1.50966422,  1.36722382,\n",
       "        0.45797239, -0.80237403, -0.14066667, -0.36866455,  0.19411689,\n",
       "       -0.95938818, -0.15629795, -0.21335731, -0.31759918,  0.14765702,\n",
       "       -0.06440698, -0.22899627, -0.74192764, -0.27817713, -0.46953741,\n",
       "       -0.75122705, -0.3036681 , -0.74527805,  0.39356196,  0.21616405,\n",
       "       -0.41861132, -0.81310819, -0.25730336, -0.02362286, -0.33285233,\n",
       "       -0.34514038, -0.29366624, -0.14792022, -0.44234176, -0.75755549,\n",
       "        1.09303408,  0.12791703,  0.34954059, -0.29952349,  0.91553083,\n",
       "       -0.92433212,  1.18081005, -0.16133169, -0.50191327, -0.27648177,\n",
       "       -0.45616709,  1.38168939, -0.39848133, -0.37803301, -0.01059299,\n",
       "        0.36912306, -0.60096693, -0.35713763, -0.83680285, -0.29819737,\n",
       "       -0.21899481,  0.24960824, -0.42558867,  0.95467735, -0.37974574,\n",
       "       -0.06150438, -0.37858049, -0.24646257,  0.30039787, -0.34707989,\n",
       "       -0.3002097 , -0.81635255, -0.08985259, -0.12883473,  0.02329247])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_snps = np.array(list(range(0, 10000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_names</th>\n",
       "      <th>feature_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3112</th>\n",
       "      <td>3112</td>\n",
       "      <td>0.200391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8984</th>\n",
       "      <td>8984</td>\n",
       "      <td>0.027190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8773</th>\n",
       "      <td>8773</td>\n",
       "      <td>0.027008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8988</th>\n",
       "      <td>8988</td>\n",
       "      <td>0.022929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6021</th>\n",
       "      <td>6021</td>\n",
       "      <td>0.019628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5860</th>\n",
       "      <td>5860</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2538</th>\n",
       "      <td>2538</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540</th>\n",
       "      <td>2540</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5857</th>\n",
       "      <td>5857</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature_names  feature_importance\n",
       "3112           3112            0.200391\n",
       "8984           8984            0.027190\n",
       "8773           8773            0.027008\n",
       "8988           8988            0.022929\n",
       "6021           6021            0.019628\n",
       "...             ...                 ...\n",
       "5860           5860            0.000000\n",
       "2538           2538            0.000000\n",
       "2540           2540            0.000000\n",
       "5857           5857            0.000000\n",
       "5000           5000            0.000000\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data={'feature_names':all_snps,'feature_importance':feature_importances}\n",
    "fi_df = pd.DataFrame(data)\n",
    "fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "fi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 250, 1557, 1680, 1777, 2160, 2191, 3013, 3498, 3609, 4236, 4585,\n",
       "       5589, 5675, 5842, 6021, 6422, 6486, 6831, 7555, 7582, 8179, 8286,\n",
       "       8773, 8848, 8984, 8988, 9398, 9741, 9862, 9879])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "causal_SNPs_1 = np.sort(causal_SNPs_list[0])\n",
    "causal_SNPs_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 231,  584,  669,  911, 1187, 1262, 1507, 1802, 2191, 2700, 3013,\n",
       "       3112, 3216, 3609, 4585, 5675, 5753, 5922, 6021, 6422, 6532, 6831,\n",
       "       7555, 8526, 8773, 8984, 8988, 9802, 9862, 9879])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_features1 = fi_df['feature_names']\n",
    "top_features1 = np.array(top_features1[0:30])\n",
    "top_features1 = np.sort(top_features1)\n",
    "top_features1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7555,\n",
       " 3013,\n",
       " 6021,\n",
       " 8773,\n",
       " 9862,\n",
       " 4585,\n",
       " 5675,\n",
       " 2191,\n",
       " 6831,\n",
       " 6422,\n",
       " 9879,\n",
       " 8984,\n",
       " 3609,\n",
       " 8988]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(top_features1).intersection(causal_SNPs_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
